# Eksamen 2023 Vår

## Oppgave 1 – Flervalgspørsmål

### 1.1

Hvilke av de følgende tillater I/O moduler og hovedminnet å utveksle data direkte?

- [ ] (a) Memory management unit (MMU)
- [x] (b) Direct memory access (DMA)
- [ ] (c) Memory address register
- [ ] (d) Alle de ovanfor
- [ ] (e) Ingen av de ovenfor

	> b) DMA

### 1.2

Hvilke av de følgende kan forklare hvorfor mer hovedminne (RAM) kan øke datamaskinen sin ytelse?

- [ ] (a) Mer RAM kan redusere den eksterne fragmenteringen
- [ ] (b) Mer RAM kan øke prosessorhastigheten
- [x] (c) Mer RAM kan redusere sannsynligheten for sidefeil
- [ ] (d) Alle de ovenfor
- [ ] (e) Ingen av de ovenfor

	> c) Mer RAM kan redusere sannsynligheten for sidefeil

### 1.3

Hvilken av de følgende vil bli lagret under et kontekstbytte mellom prosesser

- [ ] (a) Stack pointer
- [ ] (b) Program counter
- [ ] (c) CPU registers
- [x] (d) Alle de ovenfor
- [ ] (e) Ingen av de ovenfor

	> d) Alle de ovenfor

### 1.4

Hvilke av de følgende datastrukturene er generelt brukt av operativsystem for å lagre informasjon knyttet til en prosess?

- [x] (a) Process control block (PCB)
- [ ] (b) Process identifier
- [ ] (c) Process state
- [ ] (d) Alle de ovenfor
- [ ] (e) Ingen av de ovenfor

	> a) Process control block (PCB)

### 1.5

En adresse generert av CPUen er vanlegvis omtalt som en ...

- [ ] (a) Physical address
- [ ] (b) Absolute address
- [x] (c) Logical address
- [ ] (d) Alle de ovenfor
- [ ] (e) Ingen av de ovenfor

	> c) Logical address

### 1.6

Hvilke av de følgende er en fordel med virtuelt minne?

- [ ] (a) Det tillater utførelse av prosesser som ikke er fullstendig i minnet
- [ ] (b) Det abstraherer hovedminnet til et ekstremt stort logisk minne
- [ ] (c) Det tillater å kjøre program som er større enn fysisk minne
- [x] (d) Alle de ovenfor
- [ ] (e) Ingen av de ovenfor

	> d) Alle de ovenfor

### 1.7

Hvilken trådmodell tillater alle tråder å kjøre på same tid, og samtidig alle CPU-kjerner å bli utnyttet på same tid?

- [x] (a) En-til-en
- [ ] (b) En-til-mange
- [ ] (c) Mange-til-en
- [ ] (d) Mange-til-mange
- [ ] (e) Ingen av de ovenfor

	> a) En-til-en

### 1.8

Hva er en kjernetråd?

- [x] (a) En virtuell CPU som bruker-tråder er tilordnet
- [ ] (b) Det som tråder blir kalt når brukt av kernelen
- [ ] (c) Gamelt navn for tråder
- [ ] (d) Bare bruke for en-til-en tråd-modell

	> a) En virtuell CPU som bruker-tråder er tilordnet

### 1.9

Hvorfor spiller det noen rolle at mobiltelefonen din er en Von Neumann-maskin?

- [ ] (a) Det spiller ingen rolle i det hele tatt
- [x] (b) Det gjør det mulig å installere program fra app-butikker
- [ ] (c) Det betyr at den kan utføre alle operasjoner (Von Neumann-komplett)
- [ ] (d) Mobiltelefoner er generelt sett ikke Von Neumann-maskiner

	> b) Det gjør det mulig å installere program fra app-butikker

### 1.10

Hva er eksternt minne?

- [ ] (a) Lagring som er utenfor datamaskin-kabinettet
- [ ] (b) Lagring som er utenfor CPU
- [x] (c) Lagring som som ikke kan adresseres direkte fra CPU
- [ ] (d) “Hot-pluggable” lagring (kan bli koblet til en kjørendee datamaskin)

	> c) Lagring som som ikke kan adresseres direkte fra CPU

### 1.11

Hva av de følgende er er riktig om en databuss?

- [x] (a) Den har mulighet til å forbinde mer enn to enheter i et datasystem
- [ ] (b) Det kan ikke vere seriell (må ha flere parallelle datalinjer)
- [ ] (c) Den må ha stor båndbredde
- [ ] (d) Den er bare brukt til å kople CPU til hovedminne
- [ ] (e) Alle de ovenfor

	> a) Den har mulighet til å forbinde mer enn to enheter i et datasystem

### 1.12

Hva av det følgende er riktig om CPU?

- [ ] (a) En CPU-brikke kan bare ha en kjerne
- [ ] (b) En datamaskin kan bere ha en CPU-brikke
- [ ] (c) Om en datamaskin har mer enn en kjerne, så kan det bare være en CPU-brikke i datamaskinen
- [x] (d) En datamaskin kan ha flere CPU-brikker med flere kjerner hver

	> d) En datamaskin kan ha flere CPU-brikker med flere kjerner hver

## Oppgave 2 – Diverse

### 2.1

Ta utgangspunkt i et datasystem som bruker 16-bit logisk adresse. Hva er størrelsen på det logiske adresserommet?

> 2^16 = 65536 = 64Kb

### 2.2

Ta utgangspunkt i et datasystem som støtter “paging” maskinvare med en “translation look-aside buffer” (TLB).
Anta en prosess som har noen av sine forespurte sider i fysisk minne.
Sidetabellen for prosessen trenger å bli oppdatert når det det er en sidefeil.
Anta videre at prosessen forsøker å få tilgang til en side.

- **a)**
  Ta utgangspunkt i et datasystem som støtter “paging” maskinvare med en “translation look-aside buffer” (TLB).
  Anta en prosess som har noen av sine forespurte sider i fysisk minne.
  Sidetabellen for prosessen trenger å bli oppdatert når det det er en sidefeil.
  Anta videre at prosessen forsøker å få tilgang til en side.

	> en (for å hente siden)
	>
	> **Copilot** forklaring
	> Antall minnetilganger nødvendig for å hente siden om sidenummeret er funnet i TLB er 1.
	> Dette er fordi TLB er en hurtigbuffer som lagrer de siste oversettelsene av virtuelle minneadresser til fysiske adresser, så hvis sidenummeret er i TLB, kan siden hentes direkte fra minnet

- **b)**
  Hvor mange minnetilganger er nødvendig for å hente siden om sidenummeret ikke er funne i TLB og det det ikke er en sidefeil?

	> To (en for å sjekke page nummer i page table, og en for å hente fra minnet)
	>
	> **Copilot** forklaring
	> Antall minnetilganger nødvendig for å hente siden om sidenummeret ikke er funnet i TLB og det ikke er en sidefeil er 2.
	> Dette er fordi systemet først må sjekke sidetabellen for å finne den fysiske adressen til siden, og deretter hente siden fra minnet.

- **c)**
  Hvor mange tilganger til “backing store” er nødvendig om det er en sidefeil og offersiden er skitten?

	> To (one for paging out the dirty page, and one for paging in the requested page)
	>
	> **Copilot** forklaring
	> Antall tilganger til "backing store" som er nødvendig om det er en sidefeil og offersiden er skitten er 2.
	> Dette er fordi systemet først må skrive den skitne siden (en side som har blitt endret) tilbake til backing store, og deretter hente den forespurte siden fra backing store.

- **d)**
  Når en prosess bruker mer tid på “paging” enn utføring, så sier vi at prosessen ...

	> Thrashing
	>
	> **Copilot** forklaring
	> Når en prosess bruker mer tid på "paging" enn utføring, så sier vi at prosessen er i en tilstand kalt "thrashing".
	> Dette er en situasjon der systemet bruker mer tid på å bytte sider inn og ut av minnet enn på å utføre faktiske beregninger

### 2.3

Forklar forskjellene og likhetene mellom prosesser og tråder.

> En tråd deler resurser med forelder prosessen, mens prosesser er seperate.
> En child tråd kan lese og skrive til samme minnet som forelder prosessen, men en child prosess kan ikke gjøre dette.
>
> **Copilot** forklaring
> **Forskjeller**:
>> *Isolasjon*:
>> Prosesser er isolert fra hverandre og har hver sitt eget private minneområde, mens tråder innenfor samme prosess deler samme minneområde og ressurser.
>> *Kommunikasjon*:
>> Interprosesskommunikasjon er mer kompleks og tregere enn intertrådkommunikasjon, som kan gjøres direkte via delt minne.
>> *Overhead*:
>> Opprettelse, terminering og kontekstbytte av prosesser er dyrere i form av systemressurser enn for tråder.
>
> **Likheter**:
>> Begge kan utføre uavhengige oppgaver parallelt.
>> Begge har en viss form for uavhengig utførelseskontekst (for eksempel, hver tråd har sin egen stack og programteller, mens hver prosess har sin egen kopi av registerstaten og minneområdet).

### 2.4

Du har nettopp startet en ny prosess ved å bruke fork systemkallet. Hvordan kan du vite om du nå kjører i forelder eller barne-prosessen?

> fork systemkallet returnerer 0 for child prosesser, mens PID til den nye child prosessen for forelder prosessen.
>
>> **Copilot** forklaring
>> Svaret er at fork systemkallet returnerer forskjellige verdier i forelder- og barneprosessen.
>> I barneprosessen returnerer fork 0, mens i forelderprosessen returnerer det Prosess-IDen (PID) til den nye barneprosessen.
>> Så, ved å sjekke returverdien fra fork, kan du avgjøre om du er i forelder- eller barneprosessen.

### 2.5

Hva betyr det at en tråd-modell er en-til-en? Hvilke andre modeller er mulige? Forklar.

> **en-til-en**:
> I en-til-en får hver brukertråd sin egen kjernetråd. Da kan hvilken som helst tråd kjøres samtidig, men det vil ta mer resurser da det opprettes mange kjernetråder.
>
> **mange-til-en**:
> I mange-til-en kan en kjernetråd kjøre flere brukertråder, men kun en av dem om gangen.
> Hvis en brukertråd blokkerer kan kjernetråden bytte til en annen tråd.
>
> **mange-til-mange**:
> Mange-til-mange er en slags kombinasjon av en-til-en og mange-til-en.
> Dette mapper flere bruker tråder til flere kjernetråder, ikke nødvendigvis like mange.
> Dette fører til at flere av brukertrådene kan kjøre samtidig, og kan gi bedre skalering og parallellisering enn mange-til-en
>
>> **Copilot** forklaring
>> **En-til-en**:
>> I en-til-en-modellen får hver brukertråd sin egen kjernetråd. Dette betyr at hver brukertråd kan kjøres uavhengig av de andre, noe som gir god parallellitet, men det kan også føre til høy overhead hvis det er mange tråder, siden hver tråd krever sin egen kjernetråd.
>>
>> **Mange-til-en**:
>> I mange-til-en-modellen kan en enkelt kjernetråd kjøre flere brukertråder.
>> Dette betyr at hvis en brukertråd blokkerer (for eksempel venter på I/O), kan kjernetråden bytte til å kjøre en annen brukertråd.
>> Men siden det bare er en kjernetråd, kan bare en brukertråd kjøres om gangen, selv på multiprosessor-systemer.
>>
>> **Mange-til-mange**:
>> I mange-til-mange-modellen kan flere brukertråder mappes til flere kjernetråder.
>> Dette gir en god balanse mellom parallellitet (siden flere tråder kan kjøres samtidig på multiprosessor-systemer) og effektivitet (siden en blokkerende tråd ikke nødvendigvis blokkerer en hel kjernetråd).

## Oppgave 3 – Cache

### 3.1

Ta utgangspunkt i at `B0`, `B2`, `B4`, `B6` and `B8` er tilordnet til `C0`, og `B1`, `B3`, `B5`, `B7` og at `B9` er tilordnet til `C1` hvor `Bi` refererer til `i` blokk i hovedminnet og `Cj` refererer til `j` cache-linje.
Anta at `B1` og `B4` er i cache.
Hva er antall "*cache misses*" om `B8`, `B4`, `B1`, `B8`, `B1` har tilgang i den viste rekkefølgen?
Rettferdiggjør svaret ditt ved å vise hvilke tilganger som førte til "*cache miss*".

> cache: B1 B4
> B8 → cache miss, B8 erstatter B4
> B4 → cache miss, B4 erstatter B8
> B1 → cache hit
> B8 → cache miss, B8 erstatter B4
> B1 → cache hit

### 3.2

Forklar kva som er mening med cache minne.
Hva ville virkningene vært om en CPU ikke har cache minne i det hele tatt?

> Systemminnet kjører på en vesentlig mye lavere klokkehastighet enn prosessoren. Dette gjør at prosessoren må vente mye hvis den skal hente data rett fra minnet.
> Derfor har vi cache, som er en annen type minne som kjører mye kjappere, men er veldig begrenset i kapasitet.
> Det kjappere cache minnet gjør at prosessoren ikke trenger å vente like mye, og prosessoren kan jobbe mye mer effektiv.
>
>> **Copilot** forklaring
>> **Betydningen av cache-minne**:
>> Cache-minne er en type minne som er raskere, men mindre og dyrere enn hovedminnet (RAM).
>> Det brukes til å lagre data og instruksjoner som prosessoren sannsynligvis vil trenge snart, for å redusere tiden det tar å hente dem fra hovedminnet.
>> Dette kan forbedre systemets ytelse betydelig.
>>
>> **Virkningene av å ikke ha cache-minne**:
>> Hvis en CPU ikke hadde cache-minne, ville den måtte hente alle data og instruksjoner direkte fra hovedminnet.
>> Siden hovedminnet er tregere enn cache-minne, ville dette redusere systemets ytelse.
>> I tillegg ville det ikke være noen måte å utnytte lokalitet i programmets adferd (det vil si, tendensen til at programmer ofte aksesserer samme data eller instruksjoner flere ganger på rad), noe som også ville redusere ytelsen.

### 3.3

Du vil kjøpe en ny datamaskin.
Du vurderer en modell med flere muligheter for mengde hovedminne og cache minne (men ellers samme spesifikkasjoner).
Hva er virkningene av å øke størrelsen av cache minne sammmenlignet med å øke størrelsen på hovedminne?

> Programmet(ene) som skal kjøres vil bestemme hva som er det beste. Noen programmer krever at en har mye systemminne, mens andre trenger ikke nødvendigvis mye systemminne, men de leser ofte fra forskjellige verdier i minnet som gjør at en får ofte cache miss.
>
>> **Copilot** forklaring
>> **Øke størrelsen på cache-minne**:
>> Å øke størrelsen på cache-minne kan forbedre systemets ytelse ved å redusere antall "cache misses".
>> Dette er fordi en større cache kan lagre flere data og instruksjoner som prosessoren sannsynligvis vil trenge snart.
>> Men det er en avtagende avkastning på investeringen her, fordi jo større cachen er, jo lenger tid tar det å søke gjennom den, og jo mer strøm bruker den.
>>
>> **Øke størrelsen på hovedminne**:
>> Å øke størrelsen på hovedminne kan også forbedre systemets ytelse, spesielt for programmer som bruker mye minne.
>> Dette er fordi mer minne betyr at systemet kan holde flere programmer og data i minnet samtidig, noe som reduserer behovet for å bytte ut sider av minnet (paging).
>> Men igjen, det er en avtagende avkastning på investeringen her, fordi ikke alle programmer vil kunne utnytte det ekstra minnet, og mer minne betyr også mer strømforbruk.

### 3.4

Du utvikler noe programvare.
En kollega ser på koden din, og seier at det vil bli mange cache-miss slik du har skrevet koden.
Hva kan årsakene til dette være?

> Hvis koden gjør en operasjon på en stor mengde data, deretter så gjør den en ny operasjon på samme data kan det oppstå mange cache-miss.
> Da er det bedre om vi skriver koden slik at den gjør alle operasjonene den kan med hvert steg i dataen, før den går videre
> et eksempel på dette er om vi har en stor liste med tall, og alle tallene skal f.eks. multipliseres med 10, legges til 8 og så deles på 2.
> hvis vi da gjør hver operasjon hver for seg på alle liste elementene blir det mye cahce-miss
> hvis vi istedenfor gjør alle operasjonene for hvert tall med en gang vil det redusere cache-miss
>
>> **Copilot** forklaring
>> **Dårlig lokalitet**:
>> Hvis koden ofte aksesserer data som er spredt rundt i minnet (i stedet for å aksessere data som er nær hverandre), kan dette føre til mange "cache misses".
>> Dette er fordi cache-minne utnytter prinsippet om lokalitet, hvor data som er nær hverandre i minnet (enten i tid eller i rom) er mer sannsynlig å bli aksessert sammen.
>>
>> **Stor datamengde**:
>> Hvis koden behandler en stor mengde data som ikke passer inn i cache-minne, vil dette også føre til mange "cache misses".
>> Dette er fordi når cache-minne er fullt, må gamle data erstattes (eller "evictes") for å gjøre plass til nye data.
>>
>> **Ugunstig erstatningspolicy**:
>> Hvis cache-minne bruker en erstatningspolicy (som LRU, FIFO, etc.) som ikke passer godt med koden sin adferd, kan dette også føre til mange "cache misses".
>> For eksempel, hvis koden ofte aksesserer et sett med data som er større enn cache-minne, men mindre enn to ganger størrelsen på cache-minne, vil en LRU-policy føre til en "cache miss" for hver aksess.
>>
>> For å redusere antall "cache misses", kan du prøve å forbedre lokaliteten i koden (for eksempel ved å omorganisere datastrukturene eller endre rekkefølgen på operasjonene), redusere mengden data som behandles, eller velge en erstatningspolicy som passer bedre med koden sin adferd.

### 3.5

Typisk har en moderne CPU flere lag med cache minne.
Forklar grunnen til dette - hvorfor ikke bare et enkelt lag?

> Det er veldig vanskelig å lage minne som er veldig raskt og stabilt, og i tilleg har mye plass.
> Raskt cache minne tar også mye fysisk plass per kapasitet i forhold til treigere cache.
> Dette gjør at en også må ta dette inn i beregningen og en må velge hva som er viktigest.
> Løsningen på dette i moderne prosessorer er å ha flere "nivå" med cache.
> Den raskeste er kalt L1, og den er også den som har minst kapasitet.
> I tillegg har vi L2 og noen har også L3 cache. De har mer kapasitet, men er treigere.
>
> **Copilot** forklaring
> En moderne CPU har flere lag med cache-minne (vanligvis L1, L2 og L3) for å balansere mellom hastighet og størrelse.
> L1-cachen er den minste og raskeste, men den kan bare lagre en liten mengde data. L2- og L3-cachene er større og tregere, men de kan lagre mer data.
>
> Ved å ha flere lag med cache, kan CPUen først prøve å hente data fra den raske L1-cachen.
> Hvis dataene ikke er der (en "cache miss"), kan den prøve L2-cachen, og så videre.
> Dette betyr at CPUen ofte kan hente data fra en rask cache, men den har også tilgang til mer data i de større, men tregere cachene.
>
> Dette designet utnytter prinsippet om lokalitet: de fleste av CPUens minneaksesser er til en liten mengde data, så det gir mening å lagre denne dataen i en liten, rask cache.
> Men det er også nyttig å ha en større cache for de tilfellene der dataene ikke er i L1-cachen.

## Oppgave 4 – Assembler og adressemodi

### 4.1

Ta utgangspunkt i fragmentet med assembler-kode i Listing 1.

```assembly
push dword 1
push dword 2
push dword 3
push dword 4
pop eax - 4
mov ebx ,[esp+4] - 2
pop ecx - 3
add eax , ebx - 4 + 2 = 6
```

Anta at alle instruksjonene i Listing 1 er utført, og at “stack” vokser mot lavere adresser.

- **a)** Hva er verdien lagret i register ecx?

	> 3

- **b)** Hva er verdien lagret i register ebx?

	> 2

- **c)** Hva er verdien lagret i register eax?

	> 6

- **d)** Hva er verdien ved adressen lagret i esp?

	> 2

- **e)** Hva er verdien ved adressen lagret i esp+4?

	> 1

### 4.2

Identifiser hvilken adressemodus som blir brukt for hver av operandene i de følgende instruksjonene:

- **a)** `sub eax, 5`

	> **eax**: register
	> **5**: immediate

- **b)** `mov ebx, [eax]`

	> **ebx**: register
	> **\[eax]**: register indirect

- **c)** `mov [esp + 4], NUM`

	> **\[esp+4]**: register indirect
	> **NUM**: direct

> **Forklaring:**
>
> **Register** (Direkte eller Registerdirekte):
>> I denne modusen er operanden et register. For eksempel, i instruksjonen sub eax, 5, er eax en direkte operand.
>
> **Immediate** (Umiddelbar):
>> I denne modusen er operanden en konstant. For eksempel, i instruksjonen sub eax, 5, er 5 en umiddelbar operand.
>
> **Register Indirect** (Indirekte eller Registerindirekte):
>> I denne modusen er operanden en adresse som er lagret i et register. For eksempel, i instruksjonen mov ebx, [eax], er [eax] en indirekte operand.
>
> **Direct** (Direkte):
>> I denne modusen er operanden en direkte adresse. Dette er litt forvirrende fordi "direkte" også kan referere til registerdirekte modus. I denne konteksten betyr det at operanden "NUM" refererer direkte til en minnelokasjon, ikke en verdi lagret i et register eller en konstant

## Oppgave 5 – Prosess synkronisering

### 5.1

Typisk kan bare en prosess skrive til en kritisk seksjon på samme tid, mens det er mulig for flere prosesser å lese fra en kritisk seksjon på samme tid.
Men hva er situasjonen om en prosess ønsker å lese mens en annen ønsker å skrive til den samme kritiske seksjonen på samme tid?
Forklar.

 > Dette vil ikke fungere. Hvis det ikke er noen som skriver til en kritisk seksjon, så går det fint om flere tråder / prosesser leser fra den samtidig, da dataen ikke vil endres ved lesing.
 > Derimot vil det oppstå problemer om en prøver å lese fra en kritisk seksjon samtidig som den blir skrevet til. Da vet du ikke om dataen du leser er den gamle dataen fra *før* skrivingen skjer, eller om det er ny data fra *etter* skrivingen skjer, og man får en race condition.

### 5.2

Tre populære metoder for å beskytte en kritisk seksjon er låsar, semaforar og monitorar.
Forklar forskjeller og likheter mellom disse metodene.

> **Låser:**
> En lås er en enkel metode for å unngå race conditions.
> En tråd vil låse låsen, og andre tråder vil se at låsen er låst, og må vente til låsen er åpen igjen før de kan fortsette.
> Tråden som låste låsen må åpne låsen når den er ferdig.
>
> **Semaforer:**
> En semafor er ganske lik som en lås.
> Hovedforskjellen er at den har en teller som forteller hvor mange tråder som kan få tilgang samtidig.
> Når en tråd ønsker å tilgang så reduserer den telleren med 1.
> Hvis telleren er 0 så betyr det at det ikke er flere åpne plasser til denne resursen og tråden må vente.
> Når den er ferdig med resursen så må den øke telleren med 1 igjen.
>
> **Monitorer**
> En monitor har ganske lik funksjonalitet som en semafor, bortsett fra at signaler ikke "lagres" slik som semaforer og telleren den har.
> Hvis det ikke er noen tråder som venter i en wait() på et signal, så blir signalet forkastet, "glemt" av monitoren.
> Dette betyr at hvis det så kommer en ny tråd med wait() så må den vente på at det kommer et nytt signal før den kan fortsette.

### 5.3

En kollega utvikler noe programvare med to prosesser som utveksler data.
Denne personen har ikke brukt noen mekanisme for prosesssynkronisering, men sier at han/hun ikke har hatt noen problem med programvaren på tross av dette.
Forklar for denne personen hvorfor dette ikke er noen god ide, og mulige grunner for at han/hun ikke har merket noe problem.

> Det at de ikke har opplevd noe problem enda, er ikke en god nok grunn til å unngå mekanismer for prosessynkronisering.
> Når en ikke har dette så vil race conditions dukke opp, det er bare snakk om tid. Denne personen har bare vært heldig så langt.
> Det neste er at det kan godt hende de ikke har lagt merke til problemene enda. I noen programmer vil ikke alltid race conditions gjøre at programmet kræsjer, eller at det ikke funker, men kanskje den gjør mer arbeid etc. pga. verdier som leses før / etter den blir skrevet i en rekkefølge som kan skape slike problemer.
> I utgangspunktet kan en tenke at det ikke har noe å si, den ene tråden vil alltid lese før den andre pga. den andre tråden kjører med tidkrevende kode etc, men en må og huske at eksterne faktorer utenfor programmet kan også ha en innvirkning.
> Plutselig kan den raske tråden bli plassert på en treig CPU kjerne, og den treige tråden på en rask kjerne, og rekkefølgen blir annerledes.

### 5.4

Noe programvare trenger å beskytte en delt variabel.
Bare en prosess kan skrive til variabelen til samme tid, mens fleire prosessar kan lese fra den til samme tid (selvsagt bare om en annen prosess ikke skriver til den).
Skriv pseudo-kode for dette.
Du kan anta at grunnleggende funksjoner det er behov for er tilgjengeleg fra systembibliotek.

```java
int teller = 0 // teller antall lesere
boolean writelock = false // lås for skriver

Tråd leser() {
	while(writelock) { // sjekk om det er noen som skriver
		wait()
	}
	teller++
	// les fra delt variabel
	teller--
}

Tråd skriver() {
	while(teller > 0 || writelock) { // sjekk om det er noen som leser eller om skrivelås er på
		wait()
	}
	writelock = true
	// skriv til delt varabel
	writelock = false
}
```

## Oppgave 6 – CPU tidsplanlegging

### 6.1

Ta utgangspunkt i følgede tabell for prosesseringtid og periode for to periodiske prosesser P~1~ og P~2~:

| Prosess | Prosesseringtid | Periode |
| :---: | :---: | :---: |
| P~1~ | 2 | 9 |
| P~2~ | 4 | 5 |

Tidsfristen for hver av prosessene er starten på sin neste periode.
For eksempel, fristen for fullførelse for P~1~ er ved tid 9, 18, 27, ..., mens frist for fullførelse av P~2~ er ved tid 5, 10, 15, ... .
Bruk "*Første frist først*" for å tidsplanlegge de to prosessene.
Ved ***`tid = 20`***, kan de to prosessane møte alle deres frister?
Tegn Gantt-diagram av utførelsen for å rettferdiggjøre svaret.

> Ja, de klarer å møte sine deadlines som faller innenfor `tid = 20`
> ![Gant diagram 6.1](bilder/2023v-oppg6.1.bigger.svg)

### 6.2

Ta utgangspunkt i følgende tabell for prosesseringtid og periode for to periodiske prosesser P~1~ og P~2~:

| Prosess | Prosesseringtid | Periode |
| :---: | :---: | :---: |
| P~1~ | 5 | 12 |
| P~2~ | 3 | 6 |

Fristen for hver av prosessene er starten på sin neste periode.
For eksempel, fristen for fullførelse for P~1~ er ved tid 12, 24, 36, ..., mens fristen for fullførelse av P~2~ er ved tid 6, 12, 24, ... .
Bruk “*Rate-Monotonic Scheduling*” for å tidsplanlegge de to prosessene, hvor prioriteten er tilordnet basert på perioden for hver prosess: *dess kortere periode, dess høyere prioritet*.
Ved ***`tid = 24`***, kan de to prosessene møte alle deres frister?
Tegn Gantt-diagram av utførelsen for å rettferdiggjøre svaret.

> Ja, de klarer å møte alle deadlines som faller innenfor `tid = 24`
> ![Gant diagram 6.2](bilder/2023v-oppg6.2.png)

## Oppgave 7 – Sideinndeling

### 7.1

Anta at hver sidestørrelse er 2 KB (1 KB = 1024 B). Ta utgangspunkt i følgende tabell:

| Sidenummer | Rammenummer | Ramme sin startadresse |
| :---: | :---: | :---: |
| ***`i`*** | ***`j`*** | ***`k`*** |
| 5 | 4 | 8192 |
| 6 | 12 | 24576 |
| 7 | 6 | 12288 |
| 8 | 5 | 10249 |

Hver av linjene representerer en tilordning fra side ***`i`*** til ramme ***`j`***, hvor ramme ***`j`*** starter fra adresse ***`k`*** i det fysiske minnet.
For eksempel, den første linjen refererer til side 5 er tilordnet til ramme 4 som starter fra adresse 8192 i det fysiske minnet.

- **(a)**
	Skriv ned i desimaltall, sidenummeret, “offset” og den fysiske adressen for den logiske adressen 14378.

	> heltalls divisjon for å finne sidenummer

	```math
	sidenummer = 14378 / 2048 = 7
	```

	> modulo divisjon for å få rest, som er offset

	```math
	offset = 14378 \mod 2048 = 42
	```

	> ramme start adresse + offset blir fysisk adresse

	```math
	fysisk adresse = 12288 + 42 = 12330
	```

- **(b)**
	Skriv ned i desimaltall, den logiske adressen for den fysiske adressen 9216.

	> adressen er en del av side 5, fysisk adresse er innenfor side 5 sitt minneområde

	```math
	8192 + 2048 > 9216
	```

	> offset er fysisk adresse - ramme start

	```math
	offset = 9216 - 8192 = 1024
	```

	> 2048 * sidenummer for å finne logisk adresse start
	> deretter legg til offset for å finne logiske adressen

	```math
	logisk adresse = (2048 * 5) + 1024 = 11264
	```

### 7.2

Nå, anta at sidestørrelsen er 4 KB.

- **(a)**
	Om en prosess forespør 20598 byter fra operativsystemet, hvor mange sider vil prosessen bli allokert?
	Er det noen intern fragmentering?

	```math
	20598 / 4096 = 5.028
	```

	> Blir mer enn 5 sider, m å allokere 6 sider, noe som fører til at det blir intern fragmentering

	```math
	4096 - (4096*0.028) ~= 3982
	```

	> Det blir da 3982 bytes med intern fragmentering

- **(b)**
	Ta utgangspukt i et datasystem som bruker 16-bit logiske adresser.
	Hvor mange linjer er det i en sidetabell?
	Hva er størrelsen for sidetabellen?

	> bruker 16-bit logiske adresser
	> dvs at det er 2^16^ mulige adresser

	```math
	linjer = 2^{16} / 4096 = 2^{16} / 2^{12} = 2^{16-12} = 2^4 = 16
	```

	> blir 16 linjer i sidetabellen
	>
	> 16 bit = 2 bytes

	```math
	størrelse = 2 * 16 = 32
	```

	> Størrelsen på sidetabellen blir 32 bytes

## Vedlegg

### Vedlegg – ASCII-tabell (fra [asciitable.com](www.asciitable.com))

![ASCII-tabell](bilder/ascii-table.png)

### Vedlegg - Assembly Code Table

![Assembly Code Table 1](bilder/assembly-code-table-1.png)

![Assembly Code Table 2](bilder/assembly-code-table-2.png)

### Vedlegg - Linux/unix systemkall

| %eax | Name | %ebx | %ecx | %edx | %esx | %edi |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 1 | sys_exit | int | - | - | - | - |
| 2 | sys_fork | struct | pt_regs | - | - | - | - |
| 3 | sys_read | unsigned int | char * | size_t | - | - |
| 4 | sys_write | unsigned int | const char * | size_t | - | - |
| 5 | sys_open | const char * | int | int | - | - |
| 6 | sys_close | unsigned int | - | - | - | - |
